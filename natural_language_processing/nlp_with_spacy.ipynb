{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deep', 'learning', 'is', 'a', 'subset', 'of', 'Machine', 'Learning', '.']\n"
     ]
    }
   ],
   "source": [
    "# Working with String\n",
    "text = ('Deep learning is a subset of Machine Learning.')\n",
    "docs = nlp(text)\n",
    "print([token.text for token in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'man', 'is', 'born', 'free', ',', 'and', 'everywhere', 'he', 'is', 'in', 'chains', '.']\n"
     ]
    }
   ],
   "source": [
    "# Working with Files\n",
    "file_name = 'intro.txt'\n",
    "file_text = open(file_name).read()\n",
    "file_doc = nlp(file_text)\n",
    "print([token.text for token in file_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP is a part of machine learning.\n",
      "Deep leanrning is a part of machine learning.\n"
     ]
    }
   ],
   "source": [
    "sent_text = ('NLP is a part of machine learning.''Deep leanrning is a part of machine learning.')\n",
    "sent_doc = nlp(sent_text)\n",
    "sentences = list(sent_doc.sents)\n",
    "len(sentences)\n",
    "for sentence in sentences:\n",
    "    print (sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP 0\n",
      "is 4\n",
      "a 7\n",
      "part 9\n",
      "of 14\n",
      "machine 17\n",
      "learning 25\n",
      ". 33\n",
      "Deep 34\n",
      "leanrning 39\n",
      "is 49\n",
      "a 52\n",
      "part 54\n",
      "of 59\n",
      "machine 62\n",
      "learning 70\n",
      ". 78\n"
     ]
    }
   ],
   "source": [
    "for token in sent_doc:\n",
    "    print(token, token.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop Words\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['towards',\n",
       " 'such',\n",
       " 'of',\n",
       " 'did',\n",
       " 'afterwards',\n",
       " 'an',\n",
       " 'less',\n",
       " 'fifty',\n",
       " 'bottom',\n",
       " 'three']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stop_words)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP\n",
      "machine\n",
      "learning\n",
      ".\n",
      "Deep\n",
      "leanrning\n",
      "machine\n",
      "learning\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in sent_doc:\n",
    "    if not token.is_stop:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organize\n"
     ]
    }
   ],
   "source": [
    "help_text = (\"Organizing\")\n",
    "help_doc = nlp(help_text)\n",
    "for token in help_doc:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deliberate', 'progress', 'intelligent', 'human', 'like', 'artificial', 'following', 'appropriate', 'feedback', 'signal', 'able', 'define', 'evaluate', 'intelligence', 'way', 'enables', 'humans']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "complete_text = ('To make deliberate progress towards more intelligent and more human-like artificial systems,'\n",
    "                 'we need to be following an appropriate feedback signal: we need to be able to define '\n",
    "                 'and evaluate intelligence in a way that enables comparisons between two systems,' \n",
    "                 'as well as comparisons with humans.')\n",
    "\n",
    "comp_doc = nlp(complete_text)\n",
    "\n",
    "words = ([token.text for token in comp_doc\n",
    "          if not token.is_stop and not token.is_punct])\n",
    "\n",
    "word_freq = Counter(words)\n",
    "\n",
    "common_words = word_freq.most_common(5)\n",
    "#print(common_words)\n",
    "\n",
    "unique_words = [word for (word, freq) in word_freq.items() if freq == 1]\n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To TO PART infinitival \"to\"\n",
      "make VB VERB verb, base form\n",
      "deliberate JJ ADJ adjective\n",
      "progress NN NOUN noun, singular or mass\n",
      "towards IN ADP conjunction, subordinating or preposition\n",
      "more RBR ADV adverb, comparative\n",
      "intelligent JJ ADJ adjective\n",
      "and CC CCONJ conjunction, coordinating\n",
      "more RBR ADV adverb, comparative\n",
      "human JJ ADJ adjective\n",
      "- HYPH PUNCT punctuation mark, hyphen\n",
      "like JJ ADJ adjective\n",
      "artificial JJ ADJ adjective\n",
      "systems NNS NOUN noun, plural\n",
      ", , PUNCT punctuation mark, comma\n",
      "we PRP PRON pronoun, personal\n",
      "need VBP VERB verb, non-3rd person singular present\n",
      "to TO PART infinitival \"to\"\n",
      "be VB AUX verb, base form\n",
      "following VBG VERB verb, gerund or present participle\n",
      "an DT DET determiner\n",
      "appropriate JJ ADJ adjective\n",
      "feedback NN NOUN noun, singular or mass\n",
      "signal NN NOUN noun, singular or mass\n",
      ": : PUNCT punctuation mark, colon or ellipsis\n",
      "we PRP PRON pronoun, personal\n",
      "need VBP VERB verb, non-3rd person singular present\n",
      "to TO PART infinitival \"to\"\n",
      "be VB AUX verb, base form\n",
      "able JJ ADJ adjective\n",
      "to TO PART infinitival \"to\"\n",
      "define VB VERB verb, base form\n",
      "and CC CCONJ conjunction, coordinating\n",
      "evaluate VB VERB verb, base form\n",
      "intelligence NN NOUN noun, singular or mass\n",
      "in IN ADP conjunction, subordinating or preposition\n",
      "a DT DET determiner\n",
      "way NN NOUN noun, singular or mass\n",
      "that WDT DET wh-determiner\n",
      "enables VBZ VERB verb, 3rd person singular present\n",
      "comparisons NNS NOUN noun, plural\n",
      "between IN ADP conjunction, subordinating or preposition\n",
      "two CD NUM cardinal number\n",
      "systems NNS NOUN noun, plural\n",
      ", , PUNCT punctuation mark, comma\n",
      "as RB ADV adverb\n",
      "well RB ADV adverb\n",
      "as IN SCONJ conjunction, subordinating or preposition\n",
      "comparisons NNS NOUN noun, plural\n",
      "with IN ADP conjunction, subordinating or preposition\n",
      "humans NNS NOUN noun, plural\n",
      ". . PUNCT punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "for token in comp_doc:\n",
    "    print(token, token.tag_, token.pos_, spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = []\n",
    "adjective = []\n",
    "for token in comp_doc:\n",
    "    if token.pos_ == 'NOUN':\n",
    "        nouns.append(token)\n",
    "    if token.pos_ == 'ADJ':\n",
    "        adjective.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[progress,\n",
       " systems,\n",
       " feedback,\n",
       " signal,\n",
       " intelligence,\n",
       " way,\n",
       " comparisons,\n",
       " systems,\n",
       " comparisons,\n",
       " humans]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[deliberate, intelligent, human, like, artificial, appropriate, able]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "text = ('I am interested in leaning Natural Language Processing')\n",
    "text_doc = nlp(text)\n",
    "\n",
    "displacy.serve(text_doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
